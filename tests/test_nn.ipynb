{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import skew, ks_2samp # Kolmogorov-Smirnov Test\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, mean_absolute_error, r2_score \\\n",
    "                            , precision_recall_fscore_support, log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "np.array(a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    # Tags are: DET - determiner; NN - noun; V - verb\n",
    "    # For example, the word \"The\" is a determiner\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
    "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}  # Assign each tag with a unique index\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0500, -0.9256, -1.3714],\n",
      "        [-1.0188, -0.9739, -1.3419],\n",
      "        [-1.1330, -0.9662, -1.2126],\n",
      "        [-1.1818, -0.9763, -1.1501],\n",
      "        [-1.0766, -0.9916, -1.2439]])\n",
      "tensor([[-0.3892, -1.2426, -3.3890],\n",
      "        [-2.1082, -0.1328, -5.8464],\n",
      "        [-3.0852, -5.9469, -0.0495],\n",
      "        [-0.0499, -3.4414, -4.0961],\n",
      "        [-2.4540, -0.0929, -5.8799]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_gradient(data_loader, model, loss_func):\n",
    "    gradients = []\n",
    "    for inputs, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect gradients\n",
    "        for param in model.parameters():\n",
    "            gradients.append(param.grad.view(-1))\n",
    "\n",
    "    total_gradients = torch.cat(gradients)\n",
    "    return total_gradients\n",
    "\n",
    "# Example usage:\n",
    "train_gradient = capture_gradient(DataLoader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_base_on_metric(y_pred, y_true, metric):\n",
    "    supported = [[\"MSE\", \"MAE\", \"r2\"],[\"accuracy\", \"precision\", \"recall\", \"f1\"], [\"log_loss\"]]\n",
    "    if metric == \"MSE\":\n",
    "        return mean_squared_error(y_true, y_pred)\n",
    "    elif metric == \"MAE\":\n",
    "        return mean_absolute_error(y_true, y_pred)\n",
    "    elif metric == \"r2\":\n",
    "        return r2_score(y_true, y_pred)\n",
    "    elif metric == \"accuracy\":\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif metric == \"precision\":\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        return precision\n",
    "    elif metric == \"recall\":\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        return recall\n",
    "    elif metric == \"f1\":\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        return f1\n",
    "    elif metric == \"log_loss\":\n",
    "        return log_loss(y_true, y_pred)\n",
    "    else:\n",
    "        raise KeyError(\"Unsupported Metric\")\n",
    "    \n",
    "def calculate_influence_base_on_metric(base_score, current_score, metric):\n",
    "    # Errors: lower better\n",
    "    if metric in [\"MSE\", \"MAE\", \"log_loss\"]:\n",
    "        influence = current_score - base_score\n",
    "    # Accuracy: higher better\n",
    "    elif metric in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"r2\"]:\n",
    "        influence = base_score - current_score\n",
    "    else:\n",
    "        raise KeyError(\"Unsupported Metric\")\n",
    "    return influence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluenceAnalyze_PT():\n",
    "    def __init__(self, data_loader, model, loss_func):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model\n",
    "\n",
    "        self.data_category = \"tabular\"\n",
    "\n",
    "        self.data_influences = np.zeros(len(X))\n",
    "        self.feature_influences = None\n",
    "        self.influence_method = None\n",
    "\n",
    "        self.supported_tasks = [\"regression\", \"classification\", \"probabilities\"]\n",
    "        self.task = task\n",
    "        if task not in self.supported_tasks:\n",
    "            print(\"Supported tasks:\", self.supported_tasks)\n",
    "            raise KeyError(\"Unsupported Task\")\n",
    "        \n",
    "        self.supported_metrics = [[\"MSE\", \"MAE\", \"r2\"],[\"accuracy\", \"precision\", \"recall\", \"f1\"], [\"log_loss\"]]\n",
    "        self.metric = None\n",
    "\n",
    "        if metric:\n",
    "            if metric not in self.supported_metrics[self.supported_tasks.index(task)]:\n",
    "                print(f\"Supported metrics for {task}:\", self.supported_metrics[self.supported_tasks.index(task)])\n",
    "                raise KeyError(\"Unsupported Metric for this task\")\n",
    "            else:\n",
    "                self.metric = metric\n",
    "        else:\n",
    "            # Default chose the first metric\n",
    "            self.metric = self.supported_metrics[self.supported_tasks.index(task)][0]\n",
    "\n",
    "        self.preprocess_pipeline = None\n",
    "\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(self.X)\n",
    "        self.base_score = calculate_score_base_on_metric(y_pred, y, self.metric)\n",
    "\n",
    "        print(f\"Data size, X: {X.shape}, y: {y.shape}\")\n",
    "        print(f\"Task: {self.task}, using metric: {self.metric}\")\n",
    "        print(f\"Base score: {self.base_score}\")\n",
    "    \n",
    "    def help(self):\n",
    "        print(\"This calculate Influence for data\")\n",
    "        print(\"Provide data as X and target as y\")\n",
    "        print(\"Supported influence methods: LOO, shapley\")\n",
    "        print(\"Supported influence metrics: \")\n",
    "\n",
    "    def Feature_analyze(self, stat=True):\n",
    "        \"\"\"\n",
    "        This extracts each feature column to analyze the influence of each column.\n",
    "        \"\"\"\n",
    "        print(\"Analyzing each features\")\n",
    "\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        n_features = X.shape[1]\n",
    "        if n_features <= 1:\n",
    "            print(\"Data only has one feature.\")\n",
    "            return\n",
    "        # Calculate the base accuracy with all features\n",
    "        model = self.model\n",
    "\n",
    "        self.feature_influences = np.zeros(n_features)\n",
    "\n",
    "        for i in tqdm(range(n_features)):\n",
    "            X_droped = self.X.drop(self.X.columns[i], axis=1)\n",
    "\n",
    "            # fit model\n",
    "            model.fit(X_droped, y)\n",
    "            # calculate the accuracy difference as influence\n",
    "            y_pred = model.predict(X_droped)\n",
    "\n",
    "            current_score = calculate_score_base_on_metric(y_pred, y, self.metric)\n",
    "            influence = calculate_influence_base_on_metric(self.base_score, current_score, self.metric)\n",
    "            self.feature_influences[i] = influence\n",
    "\n",
    "        if stat:\n",
    "            for i in range(n_features):\n",
    "                print(f\"Column: {X.columns[i]}, influence: {self.feature_influences[i]:.4f}\")\n",
    "\n",
    "            min_feature = self.X.iloc[:, [self.feature_influences.argmin()]]\n",
    "\n",
    "            if self.feature_influences.min() >= 0:\n",
    "                print(\"All features have positive impact\")\n",
    "                return\n",
    "\n",
    "            print(f\"The feature has the worst influence: {X.columns[self.feature_influences.argmin()]}, with {self.metric} impact: {self.feature_influences.min()*100:.2f}%\")\n",
    "            print(\"Skewness of the feature:\", skew(min_feature))\n",
    "\n",
    "            sns.histplot(min_feature, kde=True)  # The `kde` parameter adds a Kernel Density Estimate plot over the histogram.\n",
    "            plt.title('Distribution')\n",
    "            plt.xlabel(X.columns[self.feature_influences.argmin()])\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "\n",
    "    def PrintInfluence(self):\n",
    "        if self.influence_method:\n",
    "            print(\"The data last used:\", self.influence_method)\n",
    "            print(self.data_influences)\n",
    "            print(\"Average influence:\", self.data_influences.mean())\n",
    "            print(\"Worst influence:\", self.data_influences.min(), \", index:\", self.data_influences.argmin())\n",
    "            print(\"The data with min influence:\")\n",
    "            print(self.X.iloc[self.data_influences.argmin()])\n",
    "        else:\n",
    "            print(\"No analysis has been done\")\n",
    "\n",
    "    def CalculateInfluence(self, method='LOO', n_random_row=10, num_shuffles=10, threshold=0.97, seed=1, stat=True):\n",
    "        n_random_row = len(self.X) if n_random_row > len(self.X) or n_random_row < 0 else n_random_row\n",
    "        if method == 'LOO':\n",
    "            self.LOOinfluence(n_random_row=n_random_row, seed=seed, stat=stat)\n",
    "        elif method == 'shapley':\n",
    "            self.shapley_influence(num_shuffles=num_shuffles, threshold=threshold, seed=seed, stat=stat)\n",
    "        else:\n",
    "            print(\"Invalid method\")\n",
    "\n",
    "    def LOOinfluence(self, n_random_row, seed=42, stat=True):\n",
    "        # Clear influences\n",
    "        self.data_influences = np.zeros(len(self.X))\n",
    "\n",
    "        print(\"Calculating data influence using Leave One Out\")\n",
    "        # To select 10 random row indexs for LOO\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        selected_indices = np.random.choice(len(self.X), n_random_row, replace=False)\n",
    "\n",
    "        influences = {}\n",
    "        # Calculate the base accuracy with all data points\n",
    "        model = self.model\n",
    "\n",
    "        # Exclue each random row to compute the LOO prediction\n",
    "        for loo_ix in tqdm(selected_indices):\n",
    "            # split data\n",
    "            X_train_loo = self.X.drop(X.index[loo_ix])\n",
    "            y_train_loo = np.delete(self.y, loo_ix)\n",
    "            # fit model\n",
    "            model.fit(X_train_loo, y_train_loo)\n",
    "            # calculate the accuracy difference as influence\n",
    "            y_pred = model.predict(X)\n",
    "            current_score = calculate_score_base_on_metric(y_pred, y, self.metric)\n",
    "            influence = calculate_influence_base_on_metric(self.base_score, current_score, self.metric)\n",
    "\n",
    "            influences[loo_ix] = influence\n",
    "            self.data_influences[loo_ix] = influence\n",
    "\n",
    "        self.influence_method = 'LOO'\n",
    "        if stat:\n",
    "            self.PrintInfluence()\n",
    "\n",
    "        return influences\n",
    "\n",
    "    def shapley_influence(self, num_shuffles=10, threshold=0.97, seed=42, stat=True):\n",
    "        \"\"\"\n",
    "        TMC based shapley inflence calculation\n",
    "        \"\"\"\n",
    "        # Clear influences\n",
    "        self.data_influences = np.zeros(len(self.X))\n",
    "\n",
    "        print(\"Calculating data influence using Shapley Value\")\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        model = self.model\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        N = X.shape[0]\n",
    "        full_performance = self.base_score\n",
    "\n",
    "        shapley_values = np.zeros(N)\n",
    "        for j in tqdm(range(num_shuffles)):\n",
    "            permutation = np.random.permutation(N)\n",
    "            X_perm = X.iloc[permutation]\n",
    "            y_perm = y[permutation]\n",
    "\n",
    "            prev_performance = 0\n",
    "            for i in tqdm(range(N)):\n",
    "                model.fit(X_perm[:i+1], y_perm[:i+1])\n",
    "                performance = accuracy_score(y, model.predict(X))\n",
    "                marginal_contribution = performance - prev_performance\n",
    "                shapley_values[permutation[i]] += marginal_contribution\n",
    "                prev_performance = performance\n",
    "\n",
    "                if performance >= threshold * full_performance:\n",
    "                    break\n",
    "\n",
    "        self.data_influences = shapley_values / num_shuffles\n",
    "        self.method = 'shapley'\n",
    "        if stat:\n",
    "            self.PrintInfluence()\n",
    "\n",
    "        return self.data_influences\n",
    "    \n",
    "    def Analyze_data_influence(self, plot=True, negative_threshold=0.15):\n",
    "        if not self.influence_method:\n",
    "            print(\"No data influence computation has been done, returning.\")\n",
    "            return\n",
    "\n",
    "        data_influences = self.data_influences\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "\n",
    "\n",
    "        negative_size = (data_influences < 0).sum()\n",
    "\n",
    "        if negative_size < negative_threshold*X.shape[0]:\n",
    "            print(\"The dataset contains mostly potive data, returning.\")\n",
    "            return\n",
    "\n",
    "        negative_data_points = X[data_influences < 0]\n",
    "        negative_targets = y[data_influences < 0]\n",
    "\n",
    "        features = X.columns\n",
    "        n_features = len(features)\n",
    "\n",
    "        if plot:\n",
    "            n_cols = int(n_features**0.5)\n",
    "            n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 5))  # Adjust size as needed\n",
    "            fig.suptitle('Feature Distributions for Overall and Negative Data Points')\n",
    "\n",
    "            # Flatten the axes array if necessary (for easy indexing)\n",
    "\n",
    "            if n_rows > 1:\n",
    "                axes = axes.flatten()\n",
    "            else:\n",
    "                axes = [axes]\n",
    "\n",
    "            # Loop through the features and plot histograms\n",
    "            for idx, feature in enumerate(features):\n",
    "                # Select the current axis\n",
    "                ax = axes[idx]\n",
    "                # Histogram for the overall dataset\n",
    "                ax.hist(X[feature].dropna(), bins=20, alpha=0.5, label='Overall', color='blue')  # Ensure to drop NA values\n",
    "                # Histogram for the negative data points\n",
    "                ax.hist(negative_data_points[feature].dropna(), bins=20, alpha=0.5, label='Negative', color='red')\n",
    "                ax.set_title(feature)\n",
    "                ax.set_xlabel(feature)\n",
    "                ax.set_ylabel('Frequency')\n",
    "                ax.legend()\n",
    "\n",
    "            # Hide any unused axes if the number of features is odd\n",
    "            if n_features % n_cols != 0:\n",
    "                for ax in axes[n_features:]:\n",
    "                    ax.axis('off')\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the rectangle in which to fit the subplots\n",
    "            plt.show()\n",
    "\n",
    "        print(\"Testing distribution different amoung negative data points and original dataset.\")\n",
    "        for feature in features:\n",
    "            # Perform Anderson-Darling test to test if the distribution of that feature is aligned \n",
    "            ks_stat, ks_pvalue = ks_2samp(X[feature].dropna(), negative_data_points[feature].dropna(), method='exact')\n",
    "\n",
    "            # print(f\"Feature: {feature}, KS Statistic: {ks_stat}, P-value: {ks_pvalue}\")\n",
    "\n",
    "            if ks_pvalue < 0.1:\n",
    "                unbalanced_feature = negative_data_points[feature]\n",
    "                print(f\"Feature {feature} distributions is statistically different.\")\n",
    "                print(f\"Consider examine data with feature {feature} with range {unbalanced_feature.mean() - unbalanced_feature.std():.3f} to {unbalanced_feature.mean() + unbalanced_feature.std():.3f}\")\n",
    "\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.hist(X[feature], bins=20, alpha=0.5, label='Overall', color='blue')\n",
    "                plt.hist(negative_data_points[feature], bins=20, alpha=0.5, label='Negative', color='red')\n",
    "                plt.title(f'{feature} Distribution')\n",
    "                plt.xlabel(feature)\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "    \n",
    "    def Auto_preprocess(self):\n",
    "        \"\"\"\n",
    "        This auto analyze data points and feature to suggestion an optimal pipeline for dataprocessing\n",
    "        \"\"\"\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        model = self.model\n",
    "        \n",
    "        if not self.feature_influences:\n",
    "            self.Feature_analyze(stat=False)\n",
    "\n",
    "        negative_features = X[X.columns[self.feature_influences < 0]]\n",
    "        \n",
    "        numeric_features = negative_features.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "        categorical_features = negative_features.select_dtypes(include=['object', 'category']).columns\n",
    "        preprocessing_steps = []\n",
    "\n",
    "        current_base_score = self.base_score\n",
    "\n",
    "        # Numeric Feature Preprocessing\n",
    "        for feature in numeric_features:\n",
    "            current_steps = preprocessing_steps\n",
    "            if X[feature].isnull().mean() > 0.1:  # Arbitrary threshold for missing data\n",
    "                preprocessing_steps.append((f'imputer_{feature}', SimpleImputer(strategy='median'), [feature]))\n",
    "                current_base_score = self.try_adding_preprocess(preprocessing_steps, current_base_score, column=feature, method='imputer')\n",
    "                \n",
    "            if X[feature].skew() > 1 or X[feature].skew() < -1:  # Check skewness\n",
    "                preprocessing_steps.append((f'scaler_{feature}', PowerTransformer(method='yeo-johnson'), [feature]))\n",
    "                current_base_score = self.try_adding_preprocess(preprocessing_steps, current_base_score, column=feature, method='scaler')\n",
    "\n",
    "            # None of the method works try removing\n",
    "            if current_steps == preprocessing_steps:\n",
    "                print(f\"None of the preprocess works for this column: {feature}. Consier removing it or examine it\")\n",
    "                \n",
    "\n",
    "        # Categorical Feature Preprocessing\n",
    "        for feature in categorical_features:\n",
    "            current_steps = preprocessing_steps\n",
    "            if X[feature].nunique() > 10:  # Arbitrary cutoff for too many categories\n",
    "                preprocessing_steps.append((f'encoder_{feature}', OneHotEncoder(handle_unknown='ignore'), [feature]))\n",
    "                current_base_score = self.try_adding_preprocess(preprocessing_steps, current_base_score, column=feature, method='encoder')\n",
    "\n",
    "            if X[feature].isnull().mean() > 0.1:\n",
    "                preprocessing_steps.append((f'imputer_{feature}', SimpleImputer(strategy='constant', fill_value='missing'), [feature]))\n",
    "                current_base_score = self.try_adding_preprocess(preprocessing_steps, current_base_score, column=feature, method='imputer')\n",
    "\n",
    "            # None of the method works try removing\n",
    "            if current_steps == preprocessing_steps:\n",
    "                print(f\"None of the preprocess works for this column: {feature}. Consier removing it or examine it\")\n",
    "\n",
    "        # Create the column transformer and pipeline\n",
    "        preprocessor = ColumnTransformer(transformers=preprocessing_steps, remainder='passthrough')\n",
    "        full_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', clone(model))])\n",
    "\n",
    "        # Fit the pipeline\n",
    "        full_pipeline.fit(X, y)\n",
    "\n",
    "        y_pred = full_pipeline.predict(X)\n",
    "        current_score = calculate_score_base_on_metric(y_pred, y, self.metric)\n",
    "\n",
    "        preprocess_influence = -calculate_influence_base_on_metric(self.base_score, current_score, self.metric)\n",
    "\n",
    "        print(f\"Preprocess pipeline: {preprocessing_steps}\")\n",
    "        print(f\"New score {current_score}, with improvement {preprocess_influence}\")\n",
    "\n",
    "        self.preprocess_pipeline = full_pipeline\n",
    "\n",
    "        return full_pipeline\n",
    "\n",
    "    def try_adding_preprocess(self, preprocessing_steps, current_base_score, column, method):\n",
    "        print(f\"Trying {method} on column: {column}\")\n",
    "        preprocessor = ColumnTransformer(transformers=preprocessing_steps, remainder='passthrough')\n",
    "        temp_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', clone(self.model))])\n",
    "        # Fit the pipeline\n",
    "        temp_pipeline.fit(self.X, self.y)\n",
    "        y_pred = temp_pipeline.predict(self.X)\n",
    "        current_score = calculate_score_base_on_metric(y_pred, y, self.metric)\n",
    "        preprocess_influence = -calculate_influence_base_on_metric(current_base_score, current_score, self.metric)\n",
    "        print(f\"This preprocess has influence: {preprocess_influence}\")\n",
    "        if preprocess_influence > 0:\n",
    "            print(\"Performance Improved, saved this preprocess\")\n",
    "            return current_score\n",
    "        else:\n",
    "            print(\"Preprocess dones't work\")\n",
    "            preprocessing_steps.pop()\n",
    "            return current_base_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
